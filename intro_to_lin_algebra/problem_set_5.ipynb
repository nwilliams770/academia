{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c656664-1751-40bd-ac05-7153c20cfb2e",
   "metadata": {},
   "source": [
    "# Problem Set 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdb71c3-8dc2-4e0c-aea4-e734c63899f5",
   "metadata": {},
   "source": [
    "## 4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a59d29-9a06-4152-a07d-0eb3a78a9578",
   "metadata": {},
   "source": [
    "6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2603ef9-ff99-4be3-b4ad-3641fd69cc9c",
   "metadata": {},
   "source": [
    "### Key Findings from the Left Null Space Problem\n",
    "\n",
    "#### 1. Understanding the Problem\n",
    "- We were given an inconsistent system $Ax = b$, meaning **no solution exists**.\n",
    "- This means that $b$ **is not in the column space** of $A$.\n",
    "- Instead of solving for $x$, we found a vector $y$ such that:\n",
    "\n",
    "  $$ y^T A = 0 \\quad \\text{(i.e., $y$ is in the left null space)} $$\n",
    "\n",
    "  but\n",
    "\n",
    "  $$ y^T b = 1. $$\n",
    "\n",
    "- This revealed a **contradiction** because it implies $b$ is **also not in the row space**.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. The Role of the Left Null Space\n",
    "- The **left null space** of $A$ consists of all solutions to $A^T y = 0$, meaning it contains vectors that are **orthogonal to the row space**.\n",
    "- If $Ax = b$ had a solution, then every vector $y$ in the left null space would satisfy:\n",
    "\n",
    "  $$ y^T b = 0. $$\n",
    "\n",
    "- But since $y^T b = 1$, **this contradicts the fact that $b$ should be in the row space**.\n",
    "\n",
    "### **Conclusion:**\n",
    "- The left null space acts as a **\"consistency check\"**:  \n",
    "  - If $y^T b \\neq 0$, then $b$ **must be outside the row space**, meaning $Ax = b$ is **inconsistent**.\n",
    "  - This is why the left null space is so powerfulâ€”it detects impossible systems.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Relationship to Matrix Rank\n",
    "- The inconsistency of $Ax = b$ tells us that **$A$ is not full rank**.\n",
    "- The dimensions of the four fundamental subspaces follow from the **Rank-Nullity Theorem**:\n",
    "\n",
    "  $$ \\dim(C(A)) + \\dim(N(A)) = n $$\n",
    "\n",
    "  $$ \\dim(C(A^T)) + \\dim(N(A^T)) = m $$\n",
    "\n",
    "  where:\n",
    "  - **$\\dim(C(A))$** = column space (number of independent columns = rank of $A$).\n",
    "  - **$\\dim(N(A))$** = null space (free variables in $Ax = 0$).\n",
    "  - **$\\dim(C(A^T))$** = row space (same as $\\dim(C(A))$).\n",
    "  - **$\\dim(N(A^T))$** = left null space (extra constraints on the system).\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Final Summary of What We Learned\n",
    "- If $Ax = b$ has **no solution**, then $b$ is **not in the column space**.\n",
    "- The **left null space** helps prove inconsistency by detecting contradictions.\n",
    "- $y$ in the **left null space** satisfies $y^T A = 0$, meaning itâ€™s **perpendicular to the row space**.\n",
    "- If $y^T b \\neq 0$, this tells us **$b$ is also not in the row space**, proving inconsistency.\n",
    "- This confirms that $A$ is **not full rank**, meaning it has a nontrivial **null space and left null space**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7192bcbd-22db-4f1f-9858-1fa25bf0ba2e",
   "metadata": {},
   "source": [
    "7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d718137e-3d13-4433-9561-99b1087eb211",
   "metadata": {},
   "source": [
    "- The problem introduces **Fredholmâ€™s Alternative**, which states:\n",
    "  - **Exactly one of these systems has a solution**:\n",
    "    $$\n",
    "    Ax = b \\quad \\text{or} \\quad A^T y = 0 \\text{ with } y^T b = 1.\n",
    "    $$\n",
    "  - If $Ax = b$ has **no solution**, there must exist a **left null space vector** $y$ such that:\n",
    "    - $A^T y = 0$ (meaning $y$ is in the **left null space**).\n",
    "    - $y^T b = 1$ (confirming inconsistency).\n",
    "\n",
    "#### Finding the Left Null Space Vector $y$\n",
    "- Instead of solving $A^T y = 0$ directly, we recognize that $y$ represents a **linear dependency among the rows of $A$**.\n",
    "- By **eyeballing how to combine rows to sum to zero**, we constructed:\n",
    "  $$\n",
    "  y = [1,1,-1].\n",
    "  $$\n",
    "- This method is valid because the **left null space consists of exactly these linear dependencies**.\n",
    "\n",
    "#### Confirming the Contradiction\n",
    "- Computing $y^T b$ gave:\n",
    "  $$\n",
    "  y^T b = 1.\n",
    "  $$\n",
    "- Since $y^T b \\neq 0$, this confirms that $b$ is **not in the row space**.\n",
    "- By **Fredholmâ€™s Alternative**, this means $Ax = b$ is **inconsistent**.\n",
    "\n",
    "#### Key Takeaway\n",
    "- **Finding a left null space vector by inspection is a valid approach**â€”it highlights dependencies without requiring row reduction.\n",
    "- If $y^T b \\neq 0$, **this guarantees that $Ax = b$ has no solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1999962b-a779-4308-a82f-7dab715d1d0f",
   "metadata": {},
   "source": [
    "9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19f0ab3-e95c-4420-ae36-b5d3d134bd06",
   "metadata": {},
   "source": [
    "#### 1. Given Statement\n",
    "We are given:\n",
    "\n",
    "$$ A^T A x = 0 $$\n",
    "\n",
    "and we need to show that this implies:\n",
    "\n",
    "$$ Ax = 0. $$\n",
    "\n",
    "This means that the **null spaces of \\( A^T A \\) and \\( A \\) are identical**.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Step-by-Step Explanation\n",
    "\n",
    "1. **Rewriting the Equation**  \n",
    "   Expanding \\( A^T A x = 0 \\):\n",
    "\n",
    "   $$\n",
    "   A^T (Ax) = 0.\n",
    "   $$\n",
    "\n",
    "   This tells us that \\( Ax \\) is in the **null space of \\( A^T \\)**.\n",
    "\n",
    "2. **Key Null Space Relationships**\n",
    "   - The **null space of \\( A \\)** is defined as:\n",
    "\n",
    "     $$\n",
    "     \\{ x \\mid Ax = 0 \\}.\n",
    "     $$\n",
    "\n",
    "   - The **null space of \\( A^T \\)** is the **left null space** of \\( A \\), meaning it consists of all vectors **orthogonal to the row space of \\( A \\)**.\n",
    "\n",
    "   - Since \\( Ax \\) is both in the **column space of \\( A \\)** and the **left null space of \\( A \\)**, the **only** possibility is:\n",
    "\n",
    "     $$\n",
    "     Ax = 0.\n",
    "     $$\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Filling in the Blanks\n",
    "From the problem statement:\n",
    "\n",
    "> \"**\\( Ax \\) is in the null space of \\( A^T \\) and also in the ____ of \\( A \\), and those spaces are ____ .**\"\n",
    "\n",
    "The correct answer is:\n",
    "\n",
    "> **\"\\( Ax \\) is in the null space of \\( A^T \\) and also in the column space of \\( A \\), and those spaces are orthogonal complements.\"**  \n",
    "\n",
    "Thus, we conclude:\n",
    "\n",
    "$$\n",
    "\\text{Null}(A^T A) = \\text{Null}(A).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Key Takeaways\n",
    "- **$A^T A$ has the same null space as $A$.**\n",
    "- This fact is fundamental in **least squares problems**, where we solve $A^T A x = A^T b $.\n",
    "- **If $A^T A$ is singular, this means $A$ has linearly dependent columns.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2843e3c2-c28e-49c7-974c-f91f3c7f1970",
   "metadata": {},
   "source": [
    "31."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b7c29b-9626-44d8-aea3-804955a2d426",
   "metadata": {},
   "source": [
    "#### 1. Understanding the Commands\n",
    "- The command $N = \\text{null}(A)$ gives a **basis for the null space of $A$**.\n",
    "- This means that the **columns** of $N$ span **$\\text{Null}(A)$**.\n",
    "\n",
    "#### 2. Why Taking $\\text{null}(N^T)$ Yields the Row Space\n",
    "- Taking $N^T$ makes the **rows of $N^T$ span $\\text{Null}(A)$**.\n",
    "- The command $B = \\text{null}(N^T)$ then **finds a basis for the subspace that is orthogonal to these rows**.\n",
    "- Since the rows **already span $\\text{Null}(A)$**, their orthogonal complement must be **$\\text{Row}(A)$**.\n",
    "\n",
    "#### 3. Key Takeaway\n",
    "- **Null space and row space are orthogonal complements.**\n",
    "- **Finding $\\text{null}(N^T)$ effectively recovers $\\text{Row}(A)$ from $\\text{Null}(A)$**.\n",
    "- This demonstrates how **iterating null space operations moves between fundamental subspaces**.\n",
    "\n",
    "\n",
    "The command $N = \\text{null}(A)$ will produce a basis for the null space of $A$.  \n",
    "Then the command $B = \\text{null}(N^T)$ will produce a basis for the **row space**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01c5064-2cd2-4ff0-9361-2caae57f63b9",
   "metadata": {},
   "source": [
    "32."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca83460c-5f42-4161-b478-29f19df70bb8",
   "metadata": {},
   "source": [
    "#### **1. The Key Condition for the Four Subspaces**\n",
    "For four vectors to serve as bases for:\n",
    "- Column space $ C(A) $,\n",
    "- Row space $ C(A^T) $,\n",
    "- Null space $ N(A) $,\n",
    "- Left null space $ N(A^T) $,\n",
    "\n",
    "each must be **one-dimensional**.  \n",
    "This forces $ A $ to have **rank 1**, because in a $ 2 \\times 2 $ matrix, the fundamental subspaces must sum to dimension 2:\n",
    "\n",
    "$$\n",
    "\\dim(C(A)) + \\dim(N(A)) = 2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\dim(C(A^T)) + \\dim(N(A^T)) = 2\n",
    "$$\n",
    "\n",
    "Thus, the matrix must have **one independent column and one independent row**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. One Possible Rank-1 Matrix**\n",
    "A rank-1 $ 2 \\times 2 $ matrix must have **dependent rows and dependent columns**, for example:\n",
    "\n",
    "$$\n",
    "A =\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "1 & 2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "which row-reduces to:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "0 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "confirming rank 1.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Why Rank 1 Forces These Dimensions**\n",
    "- The **column space** $ C(A) $ is **1D** because one column is dependent.\n",
    "- The **row space** $ C(A^T) $ is **1D** because one row is dependent.\n",
    "- The **null space** $ N(A) $ is **1D** because there is one free variable in $ Ax = 0 $.\n",
    "- The **left null space** $ N(A^T) $ is **1D** because there is one equation that is redundant.\n",
    "\n",
    "Thus, all **four fundamental subspaces** are accounted for, each having dimension 1.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Rank-Nullity Theorem Refresher**\n",
    "For an $ m \\times n $ matrix:\n",
    "- The **number of columns** $ n $ limits:\n",
    "  \n",
    "  $$\n",
    "  \\dim(C(A)) + \\dim(N(A)) = n\n",
    "  $$\n",
    "\n",
    "- The **number of rows** $ m $ limits:\n",
    "  \n",
    "  $$\n",
    "  \\dim(C(A^T)) + \\dim(N(A^T)) = m\n",
    "  $$\n",
    "\n",
    "These ensure that the four fundamental subspaces always **partition the space correctly**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. Addendum: Why Does $ A = a c r^T $ Guarantee Rank 1?**\n",
    "\n",
    "###### **The Core Idea**\n",
    "Instead of first finding the bases and constructing $ A $, we could **start with**:\n",
    "\n",
    "$$\n",
    "A = a c r^T\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ c $ is a **basis vector for the column space**.\n",
    "- $ r $ is a **basis vector for the row space**.\n",
    "- $ a \\neq 0 $ is an **arbitrary scalar**.\n",
    "\n",
    "This structure **guarantees** $ A $ is **rank 1** because:\n",
    "1. **All rows are multiples of $ r^T $** âŸ¶ The **row space is 1D**.\n",
    "2. **All columns are multiples of $ c $** âŸ¶ The **column space is 1D**.\n",
    "3. **At most one pivot in elimination** âŸ¶ The **rank must be 1**.\n",
    "4. **The null space & left null space follow naturally** âŸ¶ They are **both 1D**.\n",
    "\n",
    "---\n",
    "\n",
    "###### **6. The Orthogonality Conditions**\n",
    "For these four fundamental subspaces to be well-defined, we also require:\n",
    "\n",
    "$$\n",
    "r^T n = 0 \\quad \\text{(row space is orthogonal to null space)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "c^T \\ell = 0 \\quad \\text{(column space is orthogonal to left null space)}\n",
    "$$\n",
    "\n",
    "These conditions **guarantee** that:\n",
    "- $ n $ is **perpendicular** to the row space.\n",
    "- $ \\ell $ is **perpendicular** to the column space.\n",
    "- This follows directly from the **orthogonal complement relationships** of fundamental subspaces.\n",
    "\n",
    "Thus, these conditions **must** be true in addition to $ A = a c r^T $ to fully describe a rank-1 matrix that obeys the fundamental theorem of subspaces.\n",
    "\n",
    "---\n",
    "\n",
    "###### **7. Example Calculation**\n",
    "Letâ€™s pick a simple example with:\n",
    "\n",
    "- Column space basis: $ c = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} $\n",
    "- Row space basis: $ r = \\begin{bmatrix} 3 \\\\ 6 \\end{bmatrix} $\n",
    "- Null space basis: $ n = \\begin{bmatrix} 2 \\\\ -1 \\end{bmatrix} $ (orthogonal to $ r $)\n",
    "- Left null space basis: $ \\ell = \\begin{bmatrix} 2 \\\\ -1 \\end{bmatrix} $ (orthogonal to $ c $)\n",
    "\n",
    "Computing the **outer product**:\n",
    "\n",
    "$$\n",
    "A = c r^T =\n",
    "\\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}\n",
    "\\begin{bmatrix} 3 & 6 \\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix} 1 \\cdot 3 & 1 \\cdot 6 \\\\ 2 \\cdot 3 & 2 \\cdot 6 \\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix} 3 & 6 \\\\ 6 & 12 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Verifying **orthogonality conditions**:\n",
    "\n",
    "- $ r^T n = \\begin{bmatrix} 3 & 6 \\end{bmatrix} \\begin{bmatrix} 2 \\\\ -1 \\end{bmatrix} = 3(2) + 6(-1) = 6 - 6 = 0 $ \n",
    "- $ c^T \\ell = \\begin{bmatrix} 1 & 2 \\end{bmatrix} \\begin{bmatrix} 2 \\\\ -1 \\end{bmatrix} = 1(2) + 2(-1) = 2 - 2 = 0 $ \n",
    "\n",
    "Since both conditions hold, we confirm that **this is a valid rank-1 matrix with correctly defined fundamental subspaces**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **8. Big Takeaway**\n",
    "The form $ A = a c r^T $ is **not just a possible solutionâ€”itâ€™s the structure that defines all rank-1 matrices**.  \n",
    "This means **any rank-1 matrix** must be an **outer product** of two vectors.  \n",
    "\n",
    "Additionally, the **orthogonality conditions** $ r^T n = 0 $ and $ c^T \\ell = 0 $ ensure that the **null spaces are properly aligned** as orthogonal complements to their respective spaces.\n",
    "\n",
    "---\n",
    "\n",
    "**This is why rank-1 matrices have such a simple and structured formâ€”they can always be written as the outer product of two vectors, with their orthogonality conditions ensuring fundamental subspace structure.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0215ed-65ea-4f53-8994-ed6dfc5e8106",
   "metadata": {},
   "source": [
    "33."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eb3fe3-50e9-496d-b1a1-3d885d1f5280",
   "metadata": {},
   "source": [
    "#### **1. Understanding the Four Fundamental Subspaces**\n",
    "We are given **eight vectors**:\n",
    "- $r_1, r_2$ (basis for the **row space** $C(A^T)$)\n",
    "- $n_1, n_2$ (basis for the **null space** $N(A)$)\n",
    "- $c_1, c_2$ (basis for the **column space** $C(A)$)\n",
    "- $l_1, l_2$ (basis for the **left null space** $N(A^T)$)\n",
    "\n",
    "Each pair must:\n",
    "- **Span their respective subspace** (2D subspaces in $\\mathbb{R}^4$).\n",
    "- **Be orthogonal to their complementary subspace** (e.g., row space is orthogonal to null space).\n",
    "\n",
    "Thus, we must have:\n",
    "\n",
    "$$ r_1^T n_1 = 0, \\quad r_1^T n_2 = 0, \\quad r_2^T n_1 = 0, \\quad r_2^T n_2 = 0 $$\n",
    "\n",
    "$$ c_1^T l_1 = 0, \\quad c_1^T l_2 = 0, \\quad c_2^T l_1 = 0, \\quad c_2^T l_2 = 0 $$\n",
    "\n",
    "These conditions ensure that **each subspace is properly orthogonal to its complement.**\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Form of $A$**\n",
    "Since $A$ must have **rank 2** (two independent rows and two independent columns), it follows that all such matrices take the form:\n",
    "\n",
    "$$ A = [c_1 \\quad c_2] M [r_1 \\quad r_2]^T $$\n",
    "\n",
    "where $M$ is a **$2 \\times 2$ invertible matrix**.\n",
    "\n",
    "- The **column space is spanned by $c_1, c_2$**.\n",
    "- The **row space is spanned by $r_1, r_2$**.\n",
    "- The **invertibility of $M$ ensures the full rank of 2** (prevents dependencies that would reduce rank).\n",
    "\n",
    "If we assume **no extra transformation**, we can take $M = I$, which simplifies:\n",
    "\n",
    "$$ A = [c_1 \\quad c_2] [r_1 \\quad r_2]^T $$\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Key Takeaways**\n",
    "- The **orthogonality conditions** ensure that the subspaces are properly structured.\n",
    "- The **form of $A$ as $C R^T$ (or $C M R^T$) ensures that the row space maps to the column space**.\n",
    "- The **invertibility of $M$ ensures rank 2 is preserved**.\n",
    "- This structure **naturally enforces the fundamental theorem of subspaces**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Example**\n",
    "Letâ€™s construct an example matrix with:\n",
    "\n",
    "- $ c_1 = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\quad c_2 = \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\end{bmatrix} $\n",
    "- $ r_1 = \\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\quad r_2 = \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\\\ 1 \\end{bmatrix} $\n",
    "- Taking $M = I$, we compute:\n",
    "\n",
    "$$\n",
    "A = [c_1 \\quad c_2] [r_1 \\quad r_2]^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "A =\n",
    "\\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 0 & 0 \\\\ 0 & 0 \\end{bmatrix}\n",
    "\\begin{bmatrix} 1 & 1 \\\\ 0 & 0 \\\\ 1 & 1 \\\\ 0 & 0 \\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1 & 1 \\\\\n",
    "0 & 0 \\\\\n",
    "0 & 0 \\\\\n",
    "0 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This is an example of a **rank 2 matrix** that satisfies the conditions.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Final Thoughts**\n",
    "- This problem **generalizes the rank-1 case** from Problem 32.\n",
    "- Instead of one-dimensional subspaces, we now deal with **two-dimensional fundamental subspaces**.\n",
    "- The form $ A = C M R^T $ **captures the interaction between row and column spaces** while maintaining the necessary orthogonality conditions.\n",
    "\n",
    "Thus, this problem **illustrates how fundamental subspaces scale up in higher dimensions while preserving their key relationships**.\n",
    "\n",
    "---\n",
    "\n",
    "Let me know if you want any final tweaks! ðŸš€\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec735d5-d089-476b-8387-922ff17b5179",
   "metadata": {},
   "source": [
    "## 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3c4f83-d9ee-4de7-8fe5-cd0e65c2ea65",
   "metadata": {},
   "source": [
    "12."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027389b1-8d58-4dfd-805d-6af7614811c4",
   "metadata": {},
   "source": [
    "a.\n",
    "$$\n",
    "A =\n",
    "\\begin{bmatrix}\n",
    "1 & 1 \\\\\n",
    "0 & 1 \\\\\n",
    "0 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "A^{T}A =\n",
    "\\begin{bmatrix}\n",
    "1 & 1 \\\\\n",
    "1 & 2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P = A(A^{T}A)^{-1}A^{T} =\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "b.\n",
    "$$\n",
    "A =\n",
    "\\begin{bmatrix}\n",
    "1 & 1 \\\\\n",
    "1 & 1 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "A^{T}A =\n",
    "\\begin{bmatrix}\n",
    "2 & 2 \\\\\n",
    "2 & 3\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P = A(A^{T}A)^{-1}A^{T} =\n",
    "\\begin{bmatrix}\n",
    "0.5 & 0.5 & 0 \\\\\n",
    "0.5 & 0.5 & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda12a83-d900-4111-bd3c-c1bc1ec7e1cf",
   "metadata": {},
   "source": [
    "13."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e4f848-23f0-41f4-8396-6ee43dec31c8",
   "metadata": {},
   "source": [
    "$b = (1, 2, 3, 4)$\n",
    "$$\n",
    "P =\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$Pb = (1, 2, 3, 0)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be604ba9-e14d-4033-b08f-e6738f5b1c8b",
   "metadata": {},
   "source": [
    "16."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9307d9ac-461b-4b34-bc5d-bb898040bd1f",
   "metadata": {},
   "source": [
    "$a_1 = (1, 2, -1), a_2 = (1, 0, 1), b = (2, 1, 1)$\n",
    "\n",
    "First create a square system with $A^{T}A=$\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "6 & 0 \\\\\n",
    "0 & 2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Then compute it's inverse (for a 2x2 matrix this can be done using the determinant):\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\frac{1}{6} & 0 \\\\\n",
    "0 & \\frac{1}{2}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Next compute $A^{T}b=$\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "3 \\\\\n",
    "3\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Finally use these values to compute $p=A(A^{T}A)^{-1}A^{T}b=$\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "2 \\\\\n",
    "1 \\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The gag here is that $b$ is **already** in the column space of $A$ and thus, $Pb = b$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d72f778-831c-4195-a0a0-73e4c0084725",
   "metadata": {},
   "source": [
    "17."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7433609-9ff1-45e4-9bec-d621e5aef120",
   "metadata": {},
   "source": [
    "$(I - P)^{2} = I^{2} - PI - IP + P^{2}$\n",
    "\n",
    "We know that $I^{2} = I$ and $P^{2} = P$ and $PI = IP = P$ so we can simplify to...\n",
    "\n",
    "$I - P)^{2} = I - P$\n",
    "\n",
    "$Pb = p$ where $P$ maps a vector $b$ inside the column space of $A$ where $p$ is the best approximation of $b$ in the column space.\n",
    "\n",
    "Instead of $P$ let's use $I - P$\n",
    "\n",
    "$(I - P)b = b - Pb = b - p$\n",
    "\n",
    "This is the error vector $e = b - p$! \n",
    "\n",
    "$I - P$ removes the parts of $b$ that are in the columnspace of $A$ and what's left is in the **left null space of A**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7760ac9c-b72e-4f9c-a9a4-185aae680d25",
   "metadata": {},
   "source": [
    "19."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1656a126-2cf7-4f73-a762-738bbd271f17",
   "metadata": {},
   "source": [
    "Let $a_1 = (1, 1, 0)$ and $a_2 = (0, 2, 1)$\n",
    "\n",
    "$A=$\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "1 & 0 \\\\\n",
    "0 % 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P = A(A^{T}A)^{-1}A^{T} =\n",
    "\\begin{bmatrix}\n",
    "\\frac{5}{6} & \\frac{1}{6} & -\\frac{1}{3} \\\\\n",
    "\\frac{1}{6} & \\frac{5}{6} & \\frac{1}{3} \\\\\n",
    "-\\frac{1}{3} & \\frac{1}{3} & \\frac{1}{3}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5502f2a-0661-495f-9221-39f25591b5af",
   "metadata": {},
   "source": [
    "30."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782cfc7f-0e02-40ad-bdb5-748ebc39c563",
   "metadata": {},
   "source": [
    "a.\n",
    "\n",
    "The columns are $A$ are dependent and the column space is a line through $\\begin{bmatrix} 3 \\\\ 4 \\end{bmatrix}$\n",
    "\n",
    "$P_C = \\frac{aa^{T}}{a^{T}a} = \\frac{1}{25}\\begin{bmatrix} 9 & 12 \\\\ 12 & 16 \\end{bmatrix}$ \n",
    "\n",
    "b.\n",
    "The rows are also dependent and the row space is a line through $(1, 1, 2)$\n",
    "\n",
    "$P_R = \\frac{aa^{T}}{a^{T}a} = \\frac{1}{6}\\begin{bmatrix} 1 & 1 & 2 \\\\ 1 & 1 & 2 \\\\ 2 & 2 & 4 \\end{bmatrix}$\n",
    "\n",
    "$P_CA = A$: projecting the columns of $A$ onto the column space does not change them because they are already in the column space of $A$!\n",
    "\n",
    "$AP_R = A$ projecting the rows of $A$ onto the row space does not change them because they are already in the row space of $A$!\n",
    "\n",
    "Therefore $P_CAP_R = A$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2478f7-03d1-4eda-a93b-8ebaaeffe3bf",
   "metadata": {},
   "source": [
    "31."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1f26dc-3846-4791-8cc4-98ef6ef38d5c",
   "metadata": {},
   "source": [
    "For $p$ to be the **projection of $b$ onto the subspace spanned by $a_1, ..., a_n$**, the **error vector**:\n",
    "\n",
    "$$\n",
    "e = b - p\n",
    "$$\n",
    "\n",
    "must be **orthogonal to the column space** of $A$, where $A$ is the matrix whose columns are a basis for the subspace spanned by $a_1, ..., a_n$.\n",
    "\n",
    "To confirm $p$ is the correct projection, we check:\n",
    "\n",
    "$$\n",
    "A^T (b - p) = 0\n",
    "$$\n",
    "\n",
    "This ensures that $e$ is in the **left null space** of $A$, meaning it is perpendicular to all basis vectors of the subspace.\n",
    "\n",
    "#### **Why This Works**\n",
    "- The projection $p$ is the closest vector to $b$ in the subspace.\n",
    "- The best approximation is obtained by **minimizing the squared error**, which leads to the **normal equations**:\n",
    "\n",
    "  $$\n",
    "  A^T A x = A^T b\n",
    "  $$\n",
    "\n",
    "- If $p = A \\hat{x}$ is the projection, then the residual error $e = b - p$ must be **perpendicular** to the subspace.\n",
    "\n",
    "#### **Conclusion**\n",
    "To check if $p$ is truly the projection of $b$, compute:\n",
    "\n",
    "$$\n",
    "e = b - p\n",
    "$$\n",
    "\n",
    "and verify:\n",
    "\n",
    "$$\n",
    "A^T e = 0\n",
    "$$\n",
    "\n",
    "If this holds, then $p$ is indeed the projection of $b$ onto the subspace spanned by the $a_i$'s.\n",
    "\n",
    "This provides a **rigorous** way to verify projections, leveraging the fundamental properties of least squares and orthogonality!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bc6fdf-0ec5-489c-8ffe-e8230f07646b",
   "metadata": {},
   "source": [
    "34."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e793b6ee-1336-493f-aa2d-75f41010947c",
   "metadata": {},
   "source": [
    "Let \\( P_1 \\) and \\( P_2 \\) be projection matrices. We want to prove that \\( P_1 P_2 \\) is a projection matrix **if and only if** \\( P_1 P_2 = P_2 P_1 \\).\n",
    "\n",
    "#### **Key Idea: When Do Projections Commute?**\n",
    "A projection matrix \\( P \\) maps any vector \\( v \\) onto a subspace, keeping anything already in that subspace unchanged. That is:\n",
    "\n",
    "$$\n",
    "P v = \\text{the closest vector to } v \\text{ in the subspace}.\n",
    "$$\n",
    "\n",
    "Now, applying **two projections** in different orders:\n",
    "\n",
    "1. **\\( P_2 P_1 v \\)** first projects \\( v \\) onto the subspace of \\( P_1 \\), then onto \\( P_2 \\).\n",
    "2. **\\( P_1 P_2 v \\)** first projects \\( v \\) onto the subspace of \\( P_2 \\), then onto \\( P_1 \\).\n",
    "\n",
    "For \\( P_1 P_2 \\) to be a **projection**, applying it twice must yield the same result:\n",
    "\n",
    "$$\n",
    "(P_1 P_2)^2 = P_1 P_2.\n",
    "$$\n",
    "\n",
    "#### **Conclusion: The Commutativity Condition**\n",
    "This holds **if and only if** \\( P_1 P_2 \\) commutes:\n",
    "\n",
    "$$\n",
    "P_1 P_2 = P_2 P_1.\n",
    "$$\n",
    "\n",
    "This ensures that applying one projection first does not interfere with the other. When two projection matrices commute, their composition is also a projection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126b517e-a1f9-4d53-9abc-2720fa0d4c71",
   "metadata": {},
   "source": [
    "## 8.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285b3062-24a7-4c81-93f6-614f4454e2ed",
   "metadata": {},
   "source": [
    "13."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4cc7d6-4f25-47fd-86f6-a2ad56040873",
   "metadata": {},
   "source": [
    "To prove that $T(M) = AM$ is a **linear transformation**, check the two properties of linearity:\n",
    "\n",
    "1. **Additivity**:  \n",
    "   $$\n",
    "   T(M + N) = A(M + N) = AM + AN = T(M) + T(N)\n",
    "   $$\n",
    "   (Uses **distributive property** of matrix multiplication.)\n",
    "\n",
    "2. **Homogeneity**:  \n",
    "   $$\n",
    "   T(cM) = A(cM) = c(AM) = cT(M)\n",
    "   $$\n",
    "   (Uses **scalar multiplication property**: $A(cM) = c(AM)$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38df124-9f19-4bd8-ad5a-074344f7b6b9",
   "metadata": {},
   "source": [
    "17."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5007e303-50f8-4019-bb05-d3c985db9b83",
   "metadata": {},
   "source": [
    "\n",
    "The transformation $T$ transposes every $2 \\times 2$ matrix. We analyze the given properties:\n",
    "\n",
    "#### **(a) $T^2 = I$ (Identity Transformation)**\n",
    "Since transposing twice returns the original matrix:\n",
    "\n",
    "$$ T(T(M)) = M $$\n",
    "\n",
    "This satisfies the identity transformation condition, so **$T^2 = I$ is true**.\n",
    "\n",
    "#### **(b) The Kernel of $T$ is the Zero Matrix**\n",
    "The kernel consists of matrices $M$ such that:\n",
    "\n",
    "$$ T(M) = 0 \\quad \\Rightarrow \\quad M^T = 0 $$\n",
    "\n",
    "The only matrix that transposes to the zero matrix is the **zero matrix itself**, so **this is true**.\n",
    "\n",
    "#### **(c) Every $2 \\times 2$ Matrix is in the Range of $T$**\n",
    "The range of $T$ consists of all matrices that can be written as $M^T$ for some matrix $M$.  \n",
    "Since every matrix has a transpose, **every $2 \\times 2$ matrix is in the range**, making this **true**.\n",
    "\n",
    "#### **(d) $T(M) = -M$ is Impossible**\n",
    "This would mean:\n",
    "\n",
    "$$ M^T = -M $$\n",
    "\n",
    "which defines **skew-symmetric matrices**. However, such matrices **do exist**, for example:\n",
    "\n",
    "$$ M = \\begin{bmatrix} 0 & 1 \\\\ -1 & 0 \\end{bmatrix} $$\n",
    "\n",
    "which satisfies $M^T = -M$.  \n",
    "Thus, **this statement is false**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f88a8d-65e1-43f2-9a0a-fe76093e729a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
